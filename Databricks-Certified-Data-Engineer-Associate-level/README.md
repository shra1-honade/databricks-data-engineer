# Databricks Certified Data Engineer Associate

This repository will help you with the following 
•	Build ETL pipelines using Apache Spark SQL and Python, including:
    o	Relational entities (databases, tables, views)
    o	ELT (creating tables, writing data to tables, cleaning data, combining and reshaping tables, SQL UDFs)
    o	Python (facilitating Spark SQL with string manipulation and control flow, passing data between PySpark and Spark SQL)
•	Incrementally process data, including:
    o	Structured Streaming (general concepts, triggers, watermarks)
    o	Auto Loader (streaming reads)
    o	Multi-hop Architecture (bronze-silver-gold, streaming applications)
    o	Delta Live Tables (benefits and features)


To import these resources into your Databricks workspace, clone this repository via Databricks Repos.
